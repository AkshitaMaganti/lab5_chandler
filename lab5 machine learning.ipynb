{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4db40fb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (3,) and (4,) not aligned: 3 (dim 0) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Train the perceptron\u001b[39;00m\n\u001b[0;32m     42\u001b[0m perceptron \u001b[38;5;241m=\u001b[39m Perceptron()\n\u001b[1;32m---> 43\u001b[0m perceptron\u001b[38;5;241m.\u001b[39mtrain(X, y)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Make predictions on new customer data\u001b[39;00m\n\u001b[0;32m     46\u001b[0m new_customer_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\n\u001b[0;32m     47\u001b[0m     [\u001b[38;5;241m25\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m     48\u001b[0m ])\n",
      "Cell \u001b[1;32mIn[1], line 12\u001b[0m, in \u001b[0;36mPerceptron.train\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X)):\n\u001b[1;32m---> 12\u001b[0m         weighted_sum \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(X[i], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n\u001b[0;32m     13\u001b[0m         output \u001b[38;5;241m=\u001b[39m sigmoid(weighted_sum)\n\u001b[0;32m     14\u001b[0m         error \u001b[38;5;241m=\u001b[39m y[i] \u001b[38;5;241m-\u001b[39m output\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (3,) and (4,) not aligned: 3 (dim 0) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, learning_rate=0.1):\n",
    "        self.weights = np.random.rand(4)\n",
    "        self.bias = 0\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def train(self, X, y):\n",
    "        for epoch in range(100):\n",
    "            for i in range(len(X)):\n",
    "                weighted_sum = np.dot(X[i], self.weights) + self.bias\n",
    "                output = sigmoid(weighted_sum)\n",
    "                error = y[i] - output\n",
    "                self.weights += self.learning_rate * error * X[i]\n",
    "                self.bias += self.learning_rate * error\n",
    "\n",
    "    def predict(self, X):\n",
    "        weighted_sum = np.dot(X, self.weights) + self.bias\n",
    "        output = sigmoid(weighted_sum)\n",
    "        return output\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Load the customer data\n",
    "X = np.array([\n",
    "    [20, 6, 2],\n",
    "    [16, 3, 6],\n",
    "    [27, 6, 2],\n",
    "    [19, 1, 2],\n",
    "    [24, 4, 2],\n",
    "    [22, 1, 5],\n",
    "    [15, 4, 2],\n",
    "    [18, 4, 2],\n",
    "    [21, 1, 4],\n",
    "    [16, 2, 4]\n",
    "])\n",
    "y = np.array([1, 1, 1, 0, 1, 0, 1, 1, 0, 0])\n",
    "\n",
    "# Train the perceptron\n",
    "perceptron = Perceptron()\n",
    "perceptron.train(X, y)\n",
    "\n",
    "# Make predictions on new customer data\n",
    "new_customer_data = np.array([\n",
    "    [25, 5, 3]\n",
    "])\n",
    "predictions = perceptron.predict(new_customer_data)\n",
    "\n",
    "# Print the predictions\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30f72874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: High Value, Output: 1.00\n",
      "Prediction: High Value, Output: 1.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the data\n",
    "data = np.array([\n",
    "    [20, 6, 2, 386, 1],  # Yes\n",
    "    [16, 3, 6, 289, 1],  # Yes\n",
    "    [27, 6, 2, 393, 1],  # Yes\n",
    "    [19, 1, 2, 110, 0],  # No\n",
    "    [24, 4, 2, 280, 1],  # Yes\n",
    "    [22, 1, 5, 167, 0],  # No\n",
    "    [15, 4, 2, 271, 1],  # Yes\n",
    "    [18, 4, 2, 274, 1],  # Yes\n",
    "    [21, 1, 4, 148, 0],  # No\n",
    "    [16, 2, 4, 198, 0]   # No\n",
    "])\n",
    "\n",
    "# Initialize weights and bias with random values\n",
    "np.random.seed(0)\n",
    "weights = np.random.rand(4)\n",
    "bias = np.random.rand()\n",
    "\n",
    "# Define the sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Define the perceptron function\n",
    "def perceptron(x):\n",
    "    z = np.dot(x, weights) + bias\n",
    "    return sigmoid(z)\n",
    "\n",
    "# Define the learning rate\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Training the perceptron\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for row in data:\n",
    "        x = row[:-1]\n",
    "        y = row[-1]\n",
    "        output = perceptron(x)\n",
    "        error = y - output\n",
    "        weights += learning_rate * error * output * (1 - output) * x\n",
    "        bias += learning_rate * error * output * (1 - output)\n",
    "\n",
    "# Test the trained perceptron\n",
    "test_data = np.array([\n",
    "    [18, 3, 3, 200],  # Unknown\n",
    "    [23, 5, 2, 350]   # Unknown\n",
    "])\n",
    "\n",
    "for row in test_data:\n",
    "    output = perceptron(row)\n",
    "    if output > 0.5:\n",
    "        prediction = \"High Value\"\n",
    "    else:\n",
    "        prediction = \"Low Value\"\n",
    "    print(f\"Prediction: {prediction}, Output: {output:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "656f9e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer C_1: Actual=1, Predicted=1\n",
      "Customer C_2: Actual=1, Predicted=1\n",
      "Customer C_3: Actual=1, Predicted=1\n",
      "Customer C_4: Actual=0, Predicted=1\n",
      "Customer C_5: Actual=1, Predicted=1\n",
      "Customer C_6: Actual=0, Predicted=1\n",
      "Customer C_7: Actual=1, Predicted=1\n",
      "Customer C_8: Actual=1, Predicted=1\n",
      "Customer C_9: Actual=0, Predicted=1\n",
      "Customer C_10: Actual=0, Predicted=1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the customer data\n",
    "data = np.array([\n",
    "    [20, 6, 2, 386, 1],  # C_1 - High Value (Yes)\n",
    "    [16, 3, 6, 289, 1],  # C_2 - High Value (Yes)\n",
    "    [27, 6, 2, 393, 1],  # C_3 - High Value (Yes)\n",
    "    [19, 1, 2, 110, 0],  # C_4 - Low Value (No)\n",
    "    [24, 4, 2, 280, 1],  # C_5 - High Value (Yes)\n",
    "    [22, 1, 5, 167, 0],  # C_6 - Low Value (No)\n",
    "    [15, 4, 2, 271, 1],  # C_7 - High Value (Yes)\n",
    "    [18, 4, 2, 274, 1],  # C_8 - High Value (Yes)\n",
    "    [21, 1, 4, 148, 0],  # C_9 - Low Value (No)\n",
    "    [16, 2, 4, 198, 0]   # C_10 - Low Value (No)\n",
    "])\n",
    "\n",
    "# Initialize weights and learning rate\n",
    "num_features = 4  # Number of input features (excluding the bias term)\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "\n",
    "# Initialize weights with small random values\n",
    "weights = np.random.rand(num_features)\n",
    "\n",
    "# Define the sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Training the perceptron\n",
    "for _ in range(epochs):\n",
    "    for row in data:\n",
    "        x = row[:num_features]\n",
    "        y_true = row[num_features]\n",
    "\n",
    "        # Calculate the weighted sum of inputs\n",
    "        weighted_sum = np.dot(weights, x)\n",
    "\n",
    "        # Calculate the predicted output using the sigmoid activation function\n",
    "        y_pred = sigmoid(weighted_sum)\n",
    "\n",
    "        # Calculate the error\n",
    "        error = y_true - y_pred\n",
    "\n",
    "        # Update the weights using the gradient descent rule\n",
    "        weights += learning_rate * error * y_pred * (1 - y_pred) * x\n",
    "\n",
    "# Test the perceptron\n",
    "def predict(x):\n",
    "    weighted_sum = np.dot(weights, x)\n",
    "    y_pred = sigmoid(weighted_sum)\n",
    "    return y_pred\n",
    "\n",
    "# Print predictions for each customer\n",
    "for i, row in enumerate(data):\n",
    "    x = row[:num_features]\n",
    "    y_true = row[num_features]\n",
    "    y_pred = predict(x)\n",
    "    print(f\"Customer C_{i+1}: Actual={y_true}, Predicted={round(y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e40ef0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Error = 4.0\n",
      "Epoch 1000: Error = 4.0\n",
      "Epoch 2000: Error = 4.0\n",
      "Epoch 3000: Error = 4.0\n",
      "Epoch 4000: Error = 4.0\n",
      "Epoch 5000: Error = 4.0\n",
      "Epoch 6000: Error = 4.0\n",
      "Epoch 7000: Error = 4.0\n",
      "Epoch 8000: Error = 4.0\n",
      "Epoch 9000: Error = 4.0\n",
      "Inputs: [ 20   6   2 386], Classification: High Value\n",
      "Inputs: [ 16   3   6 289], Classification: High Value\n",
      "Inputs: [ 27   6   2 393], Classification: High Value\n",
      "Inputs: [ 19   1   2 110], Classification: High Value\n",
      "Inputs: [ 24   4   2 280], Classification: High Value\n",
      "Inputs: [ 22   1   5 167], Classification: High Value\n",
      "Inputs: [ 15   4   2 271], Classification: High Value\n",
      "Inputs: [ 18   4   2 274], Classification: High Value\n",
      "Inputs: [ 21   1   4 148], Classification: High Value\n",
      "Inputs: [ 16   2   4 198], Classification: High Value\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the customer data\n",
    "data = np.array([\n",
    "    [20, 6, 2, 386, 1],  # High Value\n",
    "    [16, 3, 6, 289, 1],  # High Value\n",
    "    [27, 6, 2, 393, 1],  # High Value\n",
    "    [19, 1, 2, 110, 0],  # Low Value\n",
    "    [24, 4, 2, 280, 1],  # High Value\n",
    "    [22, 1, 5, 167, 0],  # Low Value\n",
    "    [15, 4, 2, 271, 1],  # High Value\n",
    "    [18, 4, 2, 274, 1],  # High Value\n",
    "    [21, 1, 4, 148, 0],  # Low Value\n",
    "    [16, 2, 4, 198, 0]   # Low Value\n",
    "])\n",
    "\n",
    "# Initialize weights and bias\n",
    "np.random.seed(0)\n",
    "weights = np.random.rand(4)\n",
    "bias = np.random.rand()\n",
    "\n",
    "# Define the sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Define the learning rate and number of epochs\n",
    "learning_rate = 0.01\n",
    "epochs = 10000\n",
    "\n",
    "# Training the perceptron\n",
    "for epoch in range(epochs):\n",
    "    total_error = 0\n",
    "    for row in data:\n",
    "        inputs = row[:4]\n",
    "        target = row[4]\n",
    "\n",
    "        # Forward pass\n",
    "        z = np.dot(inputs, weights) + bias\n",
    "        predicted = sigmoid(z)\n",
    "\n",
    "        # Compute the loss (Mean Squared Error)\n",
    "        error = (predicted - target) ** 2\n",
    "        total_error += error\n",
    "\n",
    "        # Update weights and bias using gradient descent\n",
    "        d_error = 2 * (predicted - target)\n",
    "        d_predicted = predicted * (1 - predicted)\n",
    "        gradient = d_error * d_predicted\n",
    "        weights -= learning_rate * gradient * inputs\n",
    "        bias -= learning_rate * gradient\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch {epoch}: Error = {total_error}\")\n",
    "\n",
    "# Test the perceptron\n",
    "def classify(x):\n",
    "    z = np.dot(x, weights) + bias\n",
    "    predicted = sigmoid(z)\n",
    "    return \"High Value\" if predicted >= 0.5 else \"Low Value\"\n",
    "\n",
    "# Classify the data points\n",
    "for row in data:\n",
    "    inputs = row[:4]\n",
    "    classification = classify(inputs)\n",
    "    print(f\"Inputs: {inputs}, Classification: {classification}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45f31526",
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "Cannot cast ufunc 'divide' output from dtype('float64') to dtype('int32') with casting rule 'same_kind'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 18\u001b[0m\n\u001b[0;32m      4\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\n\u001b[0;32m      5\u001b[0m     [\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m386\u001b[39m, \u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m      6\u001b[0m     [\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m289\u001b[39m, \u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     [\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m198\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     15\u001b[0m ])\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Normalize the data (scaling to 0-1)\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m data[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m data[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Split data into features and labels\u001b[39;00m\n\u001b[0;32m     21\u001b[0m X \u001b[38;5;241m=\u001b[39m data[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mUFuncTypeError\u001b[0m: Cannot cast ufunc 'divide' output from dtype('float64') to dtype('int32') with casting rule 'same_kind'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the data\n",
    "data = np.array([\n",
    "    [20, 6, 2, 386, 1],\n",
    "    [16, 3, 6, 289, 1],\n",
    "    [27, 6, 2, 393, 1],\n",
    "    [19, 1, 2, 110, 0],\n",
    "    [24, 4, 2, 280, 1],\n",
    "    [22, 1, 5, 167, 0],\n",
    "    [15, 4, 2, 271, 1],\n",
    "    [18, 4, 2, 274, 1],\n",
    "    [21, 1, 4, 148, 0],\n",
    "    [16, 2, 4, 198, 0]\n",
    "])\n",
    "\n",
    "# Normalize the data (scaling to 0-1)\n",
    "data[:, :-1] /= data[:, :-1].max(axis=0)\n",
    "\n",
    "# Split data into features and labels\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "# Initialize weights and bias with random values\n",
    "np.random.seed(0)\n",
    "weights = np.random.rand(X.shape[1])\n",
    "bias = np.random.rand()\n",
    "\n",
    "# Define the sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Define the perceptron function\n",
    "def perceptron(x):\n",
    "    return sigmoid(np.dot(x, weights) + bias)\n",
    "\n",
    "# Define the Mean Squared Error (MSE) loss function\n",
    "def mse_loss(y_true, y_pred):\n",
    "    return ((y_true - y_pred) ** 2).mean()\n",
    "\n",
    "# Define the learning rate and number of epochs\n",
    "learning_rate = 0.1\n",
    "epochs = 1000\n",
    "\n",
    "# Training the perceptron\n",
    "for epoch in range(epochs):\n",
    "    y_pred = perceptron(X)\n",
    "    loss = mse_loss(y, y_pred)\n",
    "    \n",
    "    # Compute gradients\n",
    "    gradient_weights = np.dot(X.T, (y_pred - y) * y_pred * (1 - y_pred))\n",
    "    gradient_bias = np.sum((y_pred - y) * y_pred * (1 - y_pred))\n",
    "    \n",
    "    # Update weights and bias\n",
    "    weights -= learning_rate * gradient_weights\n",
    "    bias -= learning_rate * gradient_bias\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss = {loss}\")\n",
    "\n",
    "# Test the perceptron on the training data\n",
    "y_pred = perceptron(X)\n",
    "\n",
    "# Classify as \"High Value\" (1) or \"Low Value\" (0)\n",
    "y_pred_class = np.round(y_pred)\n",
    "\n",
    "# Print the predicted labels\n",
    "print(\"Predicted Labels:\", y_pred_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e481f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Value\n",
      "High Value\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the customer data\n",
    "data = np.array([\n",
    "    [20, 6, 2, 386, 1],  # High Value (Yes)\n",
    "    [16, 3, 6, 289, 1],  # High Value (Yes)\n",
    "    [27, 6, 2, 393, 1],  # High Value (Yes)\n",
    "    [19, 1, 2, 110, 0],  # Low Value (No)\n",
    "    [24, 4, 2, 280, 1],  # High Value (Yes)\n",
    "    [22, 1, 5, 167, 0],  # Low Value (No)\n",
    "    [15, 4, 2, 271, 1],  # High Value (Yes)\n",
    "    [18, 4, 2, 274, 1],  # High Value (Yes)\n",
    "    [21, 1, 4, 148, 0],  # Low Value (No)\n",
    "    [16, 2, 4, 198, 0],  # Low Value (No)\n",
    "])\n",
    "\n",
    "# Initialize weights and bias with random values\n",
    "np.random.seed(0)\n",
    "weights = np.random.rand(4)\n",
    "bias = np.random.rand(1)\n",
    "\n",
    "# Define the sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Define the learning rate\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Define the number of epochs for training\n",
    "epochs = 1000\n",
    "\n",
    "# Training the perceptron\n",
    "for _ in range(epochs):\n",
    "    for row in data:\n",
    "        x = row[:-1]\n",
    "        y_true = row[-1]\n",
    "\n",
    "        # Calculate the predicted output\n",
    "        z = np.dot(weights, x) + bias\n",
    "        y_pred = sigmoid(z)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = (y_true - y_pred)**2\n",
    "\n",
    "        # Update weights and bias using gradient descent\n",
    "        dL_dz = -2 * (y_true - y_pred) * y_pred * (1 - y_pred)\n",
    "        delta_weights = learning_rate * dL_dz * x\n",
    "        delta_bias = learning_rate * dL_dz\n",
    "\n",
    "        weights -= delta_weights\n",
    "        bias -= delta_bias\n",
    "\n",
    "# Testing the perceptron on new data\n",
    "def predict(x):\n",
    "    z = np.dot(weights, x) + bias\n",
    "    y_pred = sigmoid(z)\n",
    "    return y_pred\n",
    "\n",
    "# Make predictions on new data\n",
    "new_data = np.array([\n",
    "    [25, 5, 3, 300],  # Unknown\n",
    "    [10, 2, 1, 80],   # Unknown\n",
    "])\n",
    "\n",
    "for row in new_data:\n",
    "    prediction = predict(row)\n",
    "    if prediction >= 0.5:\n",
    "        print(\"High Value\")\n",
    "    else:\n",
    "        print(\"Low Value\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd9abdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maganti akshita\\AppData\\Local\\Temp\\ipykernel_20804\\2438505514.py:41: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -np.mean(Y * np.log(A) + (1 - Y) * np.log(1 - A))\n",
      "C:\\Users\\maganti akshita\\AppData\\Local\\Temp\\ipykernel_20804\\2438505514.py:41: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -np.mean(Y * np.log(A) + (1 - Y) * np.log(1 - A))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = nan\n",
      "Epoch 1000: Loss = nan\n",
      "Epoch 2000: Loss = nan\n",
      "Epoch 3000: Loss = nan\n",
      "Epoch 4000: Loss = nan\n",
      "Epoch 5000: Loss = nan\n",
      "Epoch 6000: Loss = nan\n",
      "Epoch 7000: Loss = nan\n",
      "Epoch 8000: Loss = nan\n",
      "Epoch 9000: Loss = nan\n",
      "Final weights: [-8.22346481  2.67404405 -5.49884066  0.72073684]\n",
      "Final bias: 0.86238001446001\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the customer data\n",
    "data = np.array([\n",
    "    [20, 6, 2, 386, 1],  # High Value (Yes)\n",
    "    [16, 3, 6, 289, 1],  # High Value (Yes)\n",
    "    [27, 6, 2, 393, 1],  # High Value (Yes)\n",
    "    [19, 1, 2, 110, 0],  # Low Value (No)\n",
    "    [24, 4, 2, 280, 1],  # High Value (Yes)\n",
    "    [22, 1, 5, 167, 0],  # Low Value (No)\n",
    "    [15, 4, 2, 271, 1],  # High Value (Yes)\n",
    "    [18, 4, 2, 274, 1],  # High Value (Yes)\n",
    "    [21, 1, 4, 148, 0],  # Low Value (No)\n",
    "    [16, 2, 4, 198, 0]   # Low Value (No)\n",
    "])\n",
    "\n",
    "# Separate the data into features (X) and labels (Y)\n",
    "X = data[:, :-1]  # Features\n",
    "Y = data[:, -1]   # Labels\n",
    "\n",
    "# Initialize weights and bias with small random values\n",
    "np.random.seed(0)\n",
    "weights = np.random.randn(4)\n",
    "bias = np.random.randn()\n",
    "\n",
    "# Define the sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Define the learning rate and number of epochs\n",
    "learning_rate = 0.01\n",
    "epochs = 10000\n",
    "\n",
    "# Training the perceptron\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    z = np.dot(X, weights) + bias\n",
    "    A = sigmoid(z)\n",
    "    \n",
    "    # Calculate the loss (cross-entropy)\n",
    "    loss = -np.mean(Y * np.log(A) + (1 - Y) * np.log(1 - A))\n",
    "    \n",
    "    # Calculate gradients\n",
    "    dz = A - Y\n",
    "    dw = np.dot(X.T, dz) / len(Y)\n",
    "    db = np.sum(dz) / len(Y)\n",
    "    \n",
    "    # Update weights and bias\n",
    "    weights -= learning_rate * dw\n",
    "    bias -= learning_rate * db\n",
    "    \n",
    "    # Print the loss every 1000 epochs\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss = {loss}\")\n",
    "\n",
    "# Final weights and bias\n",
    "print(\"Final weights:\", weights)\n",
    "print(\"Final bias:\", bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82943be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
